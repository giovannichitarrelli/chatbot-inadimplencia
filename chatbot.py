import streamlit as st
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_core.chat_history import InMemoryChatMessageHistory
import httpx
import pandas as pd
from PIL import Image
import time
import os
from dotenv import load_dotenv
from sqlalchemy import create_engine
from insights import generate_advanced_insights
from urllib.parse import quote_plus
 
load_dotenv()

api_key = os.getenv("API_KEY")
st.set_page_config(page_title="An√°lise de Inadimpl√™ncia", page_icon="")

if "app_initialized" not in st.session_state:
    st.session_state.app_initialized = False
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

def get_llm_client():
    return ChatOpenAI(
        api_key=api_key,
        base_url="https://api.deepseek.com",
        model="deepseek-chat",
        http_client=httpx.Client(verify=False)
    )

# def connect_to_db():
#     try:
#         # Dados de conex√£o
#         host = os.getenv("SERVER")
#         database = os.getenv("DATABASE")
#         username = os.getenv("USERNAME")
#         password = os.getenv("PASSWORD")
#         port = os.getenv("PORT")

#         # Validar os valores
#         if not all([host, database, username, password, port]):
#             raise ValueError("Uma ou mais vari√°veis de ambiente n√£o est√£o definidas no .env")

#         # Codificar a senha para lidar com caracteres especiais
#         encoded_password = quote_plus(password)

#         # String de conex√£o com senha codificada
#         connection_string = f"postgresql://{username}:{encoded_password}@{host}:{port}/{database}"

#         # Criar engine do SQLAlchemy
#         engine = create_engine(connection_string)

#         # Testar a conex√£o
#         with engine.connect() as connection:
#             print("Conex√£o com o banco de dados estabelecida com sucesso!")
        
#         return engine

#     except Exception as e:
#         print(f"Erro ao conectar ao banco de dados: {e}")
#         return None

def connect_to_db():
    try:
        # Verificar se est√° rodando no Streamlit Cloud (usando st.secrets) ou localmente (usando os.getenv)
        if "STREAMLIT_CLOUD" in os.environ:  # Vari√°vel fict√≠cia, ajustaremos a l√≥gica
            print("Rodando no Streamlit Cloud, usando st.secrets")
            host = st.secrets["SERVER"]
            database = st.secrets["DATABASE"]
            username = st.secrets["USERNAME"]
            password = st.secrets["PASSWORD"]
            port = st.secrets["PORT"]
        else:
            print("Rodando localmente, usando vari√°veis do .env")
            host = os.getenv("SERVER")
            database = os.getenv("DATABASE")
            username = os.getenv("USERNAME")
            password = os.getenv("PASSWORD")
            port = os.getenv("PORT")

        # Validar os valores
        if not all([host, database, username, password, port]):
            error_msg = "Uma ou mais vari√°veis de conex√£o com o banco n√£o est√£o definidas"
            print(error_msg)
            if hasattr(st, "error"):
                st.error(error_msg)
            raise ValueError(error_msg)

        # Codificar a senha para lidar com caracteres especiais
        encoded_password = quote_plus(password)

        # String de conex√£o com senha codificada
        connection_string = f"postgresql+psycopg2://{username}:{encoded_password}@{host}:{port}/{database}"

        # Criar engine do SQLAlchemy
        engine = create_engine(connection_string)

        # Testar a conex√£o
        with engine.connect() as connection:
            success_msg = "Conex√£o com o banco de dados estabelecida com sucesso!"
            print(success_msg)
        
        return engine

    except Exception as e:
        error_msg = f"Erro ao conectar ao banco de dados: {e}"
        print(error_msg)
        if hasattr(st, "error"):
            st.error(error_msg)
        return None

def classify_user_intent(prompt, llm):
    """
    Classifica a inten√ß√£o do usu√°rio para determinar o tipo de consulta necess√°ria
    """
    intent_prompt = ChatPromptTemplate.from_messages([
        ("system", """
        Analise a pergunta do usu√°rio sobre inadimpl√™ncia e classifique a inten√ß√£o em uma das seguintes categorias:
        1. COMPARA√á√ÉO - Perguntas que comparam diferentes aspectos (ex: "Compare PF e PJ")
        2. RANKING - Perguntas sobre "maior", "menor", "top", etc. (ex: "Qual estado com maior inadimpl√™ncia?")
        3. ESPEC√çFICO - Perguntas sobre um atributo espec√≠fico (ex: "Valor de inadimpl√™ncia em S√£o Paulo")
        4. TEND√äNCIA - Perguntas sobre evolu√ß√£o temporal (ex: "Como evoluiu a inadimpl√™ncia")
        5. GERAL - Perguntas gerais sobre inadimpl√™ncia
        
        Responda apenas com o n√∫mero da categoria mais adequada (1, 2, 3, 4 ou 5).
        """),
        ("human", "{input}")
    ])
    
    intent_chain = intent_prompt | llm
    intent_result = intent_chain.invoke({"input": prompt})
    
    # Extrair apenas o n√∫mero da classifica√ß√£o
    intent_number = ''.join(filter(str.isdigit, intent_result.content[:2]))
    
    intent_mapping = {
        "1": "COMPARA√á√ÉO",
        "2": "RANKING",
        "3": "ESPEC√çFICO",
        "4": "TEND√äNCIA",
        "5": "GERAL"
    }
    
    return intent_mapping.get(intent_number, "GERAL")

def generate_dynamic_query(intent, prompt, llm, table_name="table_agg_inad_consolidado"):
    """
    Gera uma consulta SQL din√¢mica com base na inten√ß√£o do usu√°rio e na pergunta
    """
    query_prompt = ChatPromptTemplate.from_messages([
        ("system", f"""
        Voc√™ √© um especialista em SQL que transforma perguntas sobre inadimpl√™ncia em consultas SQL precisas.
        
        A tabela principal √© '{table_name}' e cont√©m as seguintes colunas:
        - cliente_tipo (PF, PJ)
        - cliente_porte (Pequeno, M√©dio, Grande)
        - cliente_ocupacao (para PF: v√°rias ocupa√ß√µes)
        - cliente_setor (para PJ: v√°rios setores)
        - estado (siglas dos estados brasileiros)
        - modalidade (tipos de opera√ß√µes de cr√©dito)
        - valor_inadimplencia (valor em reais)
        - num_operacoes (quantidade de opera√ß√µes)
        - data_referencia (m√™s de refer√™ncia dos dados)
        
        A inten√ß√£o do usu√°rio foi classificada como: {intent}
        
        Com base nesta inten√ß√£o e na pergunta abaixo, gere uma consulta SQL que retorne os dados necess√°rios.
        Para consultas de RANKING, use ORDER BY e LIMIT.
        Para consultas de COMPARA√á√ÉO, use GROUP BY para os itens comparados.
        Para consultas ESPEC√çFICAS, use filtros WHERE adequados.
        Para consultas de TEND√äNCIA, considere agrupamentos por per√≠odos.
        
        IMPORTANTE: Retorne APENAS o c√≥digo SQL, sem explica√ß√µes ou coment√°rios.
        """),
        ("human", "{input}")
    ])
    
    query_chain = query_prompt | llm
    sql_result = query_chain.invoke({"input": prompt})
    
    # Limpar a resposta para garantir que seja apenas SQL

    sql_query = sql_result.content.strip()
    if sql_query.startswith("```sql"):
        sql_query = sql_query.replace("```sql", "").replace("```", "").strip()
    
    return sql_query

def process_question_with_insights(prompt, intent, dynamic_query, df, insights, llm):
    """
    Processa a pergunta usando insights est√°ticos e dados din√¢micos da consulta
    """
    # Executar a consulta din√¢mica
    try:
        dynamic_results = pd.read_sql(dynamic_query, df.con) if hasattr(df, 'con') else df.query(dynamic_query) if "SELECT" not in dynamic_query.upper() else pd.read_sql(dynamic_query, create_engine("sqlite:///:memory:"), params={})
    except Exception as e:
        print(f"Erro ao executar consulta din√¢mica: {e}")
        # Fallback para insights est√°ticos
        dynamic_results = "N√£o foi poss√≠vel gerar resultados din√¢micos espec√≠ficos."
    
    # Preparar o contexto combinado
    processing_prompt = ChatPromptTemplate.from_messages([
        ("system", f"""
        Voc√™ √© um especialista em an√°lise de inadimpl√™ncia no Brasil.
        
        A pergunta do usu√°rio foi classificada como: {intent}
        
        Responda √† pergunta usando estas duas fontes de informa√ß√£o:
        
        1. INSIGHTS PR√â-CALCULADOS:
        {insights}
        
        2. RESULTADOS DIN√ÇMICOS DA CONSULTA:
        {dynamic_results}
        
        Priorize os resultados din√¢micos pois s√£o mais relevantes para a pergunta espec√≠fica.
        Use os insights pr√©-calculados para complementar sua resposta com contexto adicional.
        
        Formate os valores em reais (R$) com duas casas decimais e separadores de milhar.
        Seja conciso e direto, destacando os pontos mais relevantes para a pergunta do usu√°rio.
        """),
        ("human", "{input}")
    ])
    
    processing_chain = processing_prompt | llm
    response = processing_chain.invoke({"input": prompt})
    
    return response.content

def main():
    st.title("Chatbot Inadimplinha")
    st.caption("Chatbot Inadimplinha desenvolvido por Grupo de Inadimpl√™ncia EY")

    # Conectar ao banco de dados
    conn = connect_to_db()
    if conn is None:
        st.stop()
    
    # Inicializar o modelo LLM
    llm = get_llm_client()
    
    # Carregar os dados do banco e gerar insights apenas uma vez
    if "insights" not in st.session_state or "df" not in st.session_state:
        try:
            # Carregar os dados
            table = "table_agg_inad_consolidado"
            query = f"SELECT * FROM {table}"
            df = pd.read_sql(query, conn)
            st.session_state.df = df
            
            # Gerar insights
            st.session_state.insights = generate_advanced_insights(df)
            
            print(f"Total de linhas carregadas do banco: {len(df)}")
            print(f"Primeiras linhas do DataFrame:\n{df.head()}")
        except Exception as e:
            st.error(f"Erro ao carregar dados ou gerar insights: {str(e)}")
            conn.dispose()
            st.stop()
    
    # Criar a cadeia de execu√ß√£o padr√£o para casos simples
    prompt_template = ChatPromptTemplate.from_messages([
        ("system", (
            "Voc√™ √© um especialista em an√°lise de inadimpl√™ncia no Brasil. "
            "Responda a pergunta do usu√°rio com base nos dados reais de dezembro de 2024 da tabela 'table_agg_inad_consolidado', "
            "usando os insights detalhados abaixo como fonte principal. "
            "Os insights foram gerados a partir dos dados reais do banco e cont√™m valores totais e an√°lises segmentadas. "
            "Extraia a resposta diretamente dos insights quando poss√≠vel, sem inventar valores. "
            "Se a pergunta n√£o for respondida pelos insights ou se os insights indicarem que n√£o h√° dados, "
            "informe que os dados de dezembro de 2024 n√£o est√£o dispon√≠veis e sugira verificar a fonte. "
            "Formate os valores em reais (R$) com duas casas decimais e separadores de milhar. "
            "Inclua informa√ß√µes adicionais relevantes sobre inadimpl√™ncia quando apropriado.\n\n"
            "Insights gerados:\n{insights}"
        )),
        ("human", "{input}")
    ])
    
    chain = prompt_template | llm

    # Inicializar o hist√≥rico de mensagens
    if "chat_history_store" not in st.session_state:
        st.session_state.chat_history_store = InMemoryChatMessageHistory()

    # Envolver a cadeia com hist√≥rico de mensagens
    conversation = RunnableWithMessageHistory(
        runnable=chain,
        get_session_history=lambda: st.session_state.chat_history_store,
        input_messages_key="input",
        history_messages_key="chat_history"
    )

    # Adicionar mensagem inicial apenas uma vez
    if not st.session_state.app_initialized and not st.session_state.chat_history:
        initial_message = "Como posso te ajudar hoje?"
        st.session_state.chat_history.append({"role": "assistant", "content": initial_message})
        st.session_state.chat_history_store.add_ai_message(initial_message)
        st.session_state.app_initialized = True

    # Exibir hist√≥rico de chat para o usu√°rio
    for message in st.session_state.chat_history:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("Fa√ßa uma pergunta sobre a inadimpl√™ncia"):
        # Adicionar a pergunta do usu√°rio √† interface de chat
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # Adicionar √† exibi√ß√£o do hist√≥rico
        st.session_state.chat_history.append({"role": "user", "content": prompt})
        
        # Processar a resposta
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            
            try:
                with st.spinner(""):
                    # Classificar a inten√ß√£o do usu√°rio
                    intent = classify_user_intent(prompt, llm)
                    print(f"Inten√ß√£o classificada como: {intent}")
                    
                    # Gerar consulta din√¢mica baseada na inten√ß√£o
                    dynamic_query = generate_dynamic_query(intent, prompt, llm)
                    print(f"Consulta din√¢mica gerada: {dynamic_query}")
                    
                    # Processar a pergunta com insights e resultados din√¢micos
                    if intent != "GERAL":
                        response_content = process_question_with_insights(
                            prompt, 
                            intent, 
                            dynamic_query, 
                            st.session_state.df, 
                            st.session_state.insights,
                            llm
                        )
                    else:
                        # Para perguntas gerais, usar o fluxo padr√£o
                        response = conversation.invoke(
                            {"input": prompt, "insights": st.session_state.insights},
                            config={"configurable": {"session_id": "default"}}
                        )
                        response_content = response.content
                    
                    # Simulando streaming para melhor UX
                    full_response = ""
                    for i in range(len(response_content)):
                        full_response = response_content[:i+1]
                        message_placeholder.markdown(full_response + "‚ñå")
                        time.sleep(0.01)
                    message_placeholder.markdown(full_response)
                    
                    # Adicionar √† exibi√ß√£o do hist√≥rico
                    st.session_state.chat_history.append({"role": "assistant", "content": full_response})
                    st.session_state.chat_history_store.add_ai_message(full_response)
                
            except Exception as e:
                error_message = f"Erro no processamento: {str(e)}"
                message_placeholder.markdown(error_message)
                st.session_state.chat_history.append({"role": "assistant", "content": error_message})
                st.session_state.chat_history_store.add_ai_message(error_message)

    with st.sidebar:
        ey_logo = Image.open(r"EY_Logo.png")
        ey_logo_resized = ey_logo.resize((100, 100))   
        st.sidebar.image(ey_logo_resized)
        st.sidebar.header("EY Academy | Inadimpl√™ncia")

        st.sidebar.subheader("üîç Sugest√µes de An√°lise")
        st.sidebar.write("‚û°Ô∏è Qual estado com maior inadimpl√™ncia e quais os valores devidos?")
        st.sidebar.write("‚û°Ô∏è Qual tipo de cliente apresenta o maior n√∫mero de opera√ß√µes?")
        st.sidebar.write("‚û°Ô∏è Em qual modalidade existe maior inadimpl√™ncia?")
        st.sidebar.write("‚û°Ô∏è Compare a inadimpl√™ncia entre PF e PJ")
        st.sidebar.write("‚û°Ô∏è Qual ocupa√ß√£o entre PF possui maior inadimpl√™ncia?")
        st.sidebar.write("‚û°Ô∏è Qual o principal porte de cliente com inadimpl√™ncia entre PF?")
        
        # Bot√£o para limpar hist√≥rico de conversa
        if st.button("Limpar Conversa"):
            st.session_state.chat_history_store = InMemoryChatMessageHistory()
            st.session_state.chat_history = []
            st.session_state.app_initialized = False
            st.rerun()

    conn.dispose()  # Fechar o engine ao final da execu√ß√£o

if __name__ == "__main__":
    main()


